<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[IE ]]></title><description><![CDATA[Ilya Eckstein's blog]]></description><link>https://ilyaeck.github.io</link><generator>RSS for Node</generator><lastBuildDate>Fri, 16 Sep 2016 21:21:21 GMT</lastBuildDate><atom:link href="https://ilyaeck.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Natural language understanding: How deep is too deep?]]></title><description><![CDATA[<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><strong>TL;DR</strong> Is Deep Learning always the best tool for Natural Language Understanding tasks? Not necessarily!</p>
</div>
<div class="paragraph">
<p>Recently, a paper from Facebook AI Research (FAIR) appeared on arXiv, under the intriguing title <a href="https://arxiv.org/pdf/1607.01759v2.pdf"><em>Bag of Tricks for Efficient Text Classification</em></a>[1], promptly catching the NLP community&#8217;s attentuion. Even more intruguingly, FAIR soon followed up with an open source implementation a.k.a. <a href="https://github.com/facebookresearch/fastText">fastText</a>[2]. In this work (essentially a simple modification of the unsupervised <a href="https://en.wikipedia.org/wiki/Word2vec">Word2Vec</a> algorithm to deal with supervised learning tasks), the authors made a convincing case for the frequent superiority of _shallow*
networks - as opposed to deep ones - for common text understandig tasks such as sentence classification, dispelling the myth that "deeper is always better".
Furthermore, this paper is but one example in the recent slew of results casting the "silver bullet" efficacy of complex neural architectures into question for text-related tasks (see some examples here[3], here[4] and here[5]).</p>
</div>
<div class="paragraph">
<p>Surprised? After all, isn&#8217;t Deep Learning a new disruptive force in AI, shown beyond doubt to be clearly superior to prior "shallow"
learning approaches? Well, it depends who you ask. Ask a Computer Vision or a Speech Recognition expert, and you&#8217;ll get and enthusiastic Yes!
In computer vision, novel DL archirectures (such as <a href="https://arxiv.org/abs/1409.1556">VGG</a>, <a href="https://arxiv.org/abs/1409.4842">GoogleNet</a>, <a href="https://arxiv.org/abs/1512.00567">Inception</a>, etc.) have delivered extremely impressive
results on benchmarks such as <a href="http://image-net.org/">ImageNet</a> and <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a>, even defying expectations of some computer vision DL champions[5]. In speech, commercial heavyweights such as Google and Baidu have longs since switch to DL architectures. It should only be natural to expect, then, to see the
same trend in NLP/NLU, correct? Well, not so fast.</p>
</div>
<div class="paragraph">
<p>The tide of enthusiasm in Deep Learning has of course spilled over to the NLU community, triggering a massive conversion of both
academics and industry practitioners to the newfound DL religion. Impressive results from other fields,
helped by the success of the seminal Word2Vec[6] (followed by Glove[7] and the like) was too much to resist. RNN and LSTM have since become mainstream techniques, offered by
popular DL libraries such as TensorFlow, Keras, DL4J, etc. Among other big companies, Google has been at the forefront of both open-sourcing DL techniques (with <a href="https://www.tensorflow.org/">TensorFlow</a>) and adopting DL architectures in production (in the NLU domain, <a href="https://gmail.googleblog.com/2015/11/computer-respond-to-this-email.html">SmatrtReply</a>[9] is one recent example).</p>
</div>
<div class="paragraph">
<p>So - you ask - isn&#8217;t that enough? Where do I sign up?! Well, dear friend: if you are reading this, chances are, you are not Google and you likely have neither similarly massive amounts of training data nor their virtually unlimited computational resources. For the rest of us, it is important to understand the performance/computation tradeoffs that come with DL - which is what this post is really about. So let us look at some key problems one by one. In this post, we will focus on text classification.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="__ext_classification">Тext Classification</h3>
<div class="paragraph">
<p>Clearly, text classification is a common task with plenty of applications: search, user intent determination, sentiment analysis, topic modeling
(slightly different, but close), seqeuence labeling (related), etc.
For text classification, we typically have 3 options:</p>
</div>
<div class="ulist disc">
<ul class="disc">
<li>
<p>Good old classifiers such as Random Forests (RF) or Logistic Regression (LR). In this case, we&#8217;ll typically use a Bag of Word (BoW) representation such as TF/IDF.</p>
<div class="ulist">
<ul>
<li>
<p>Pros: well understood models, relatively intutitive features you can control, speed.</p>
</li>
<li>
<p>Cons: the features are "semantically blind": we&#8217;ll miss any words or synonyms that are not in the training set. Also, to push performance, manual feature engineering may be required.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Shallow Neural Networks (NNs) such as Facebook&#8217;s <a href="https://github.com/facebookresearch/fastText">fastText</a>.</p>
<div class="ulist">
<ul>
<li>
<p>Pros: still fast, no feature engineering, possibly inherits Word2Vec&#8217;s nice semantic properties (more on that below).</p>
</li>
<li>
<p>Cons: relatively black box (as all NNs are, whether deep or shallow): little intuition or control over the features.</p>
</li>
<li>
<p>Insights:  whether deep or shallow, there is one important distinction about NNs. Many traditional classification methods aim to learn a feature space partitioning function
(as a means to separate samples of different classes), leaving feature engineering to the application developer. Conversely, NNs
actually do more than that: they seek to <em>learn the optimal representation</em> (read: N-dimensional vector encoding of your data points:
words, sentences, paragraphs, what have you&#8230;&#8203;) so as to minimize some loss function on the training set. That learned representation is a byproduct that can sometimes be more valuable than the main task! For instance, in <a href="https://en.wikipedia.org/wiki/Word2vec">Word2Vec</a>, the task is predicting a word based on the words around it (or vice-versa), which admittedly is not a very common problem in reality. However, as a byproduct, we get word vectors with some interesting semantic properties (e.gt) that become handy in text classification and other application.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Deep neural networks such as RNNs/LSTMs or ConvNets. Let us discuss this option in more detail below.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Recurrent Neural Networks (RNNs) are category of NN-based models designed specifically for <em>sequences of arbitrary length</em>. Which makes particularly attractive tool for modeling text.
(2 sentences on RNN + picture: vector representation, etc.). However, in practice, RNNs can be hard to train and for small to medium-sized training datasest: again, good old RF or LR can often deliver similar or even superior
performance at a lower computational cost. Even in the Deep Learning category, RNNs have a strong competitor in Convolutional Neural Nets
(a.k.a. ConvNets or CNNs) - just as long as your text can be treated as fixed length sequences, making them a suitable approach to represent and classify tweets, text messages, short user reviews, etc. Still, it&#8217;s too early to dismiss RNNs and their variants entirely. Where these networks (and particularly their more advanced variant called <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Long-Short Memory Networks or LSTMs</a>) begin to shine are other NLU tasks that often involve prediction (i.e., generative in nature) rather than "just" classification, a fundamentally discriminative task. So, let us look beyond classification.</p>
</div>
</div>
<div class="sect2">
<h3 id="_language_modeling">Language modeling</h3>
<div class="paragraph">
<p>Language modeling is a fundamental NLP task, central to important problems such as speech recognition and machine translation and instrumental in many other settings. In simple terms, the goal is, given a sequence of symbols (words or characters), to predict the next symbol (word or character), sometimes more than one. Ever experienced Google&#8217;s search query autocomplete? There you go!</p>
</div>
<div class="paragraph">
<p>It turns out that RNN/LSTM networks by now have a clear edge over n-gram baseline methods when it comes to predicting sequences. Karpathy&#8217;s now famous post, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The unreasonable effectiveness of recurrent neural networks</a> has given us a glimpse into the power of character-based RNN language models, showcasing their "magic" in generating Shakespeare-like text and beyond - although as some people pointed out, some prior techniques are in fact capable of similar magic. Still, it as already been shown[10] that RNNs are capable of dramatically better performance, improving the language model <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> by <strong>2x</strong> over prior baselines -  even on large one-billion-words datasets. The caveat is expensive computation, but as GPUs keep getting cheaper, that&#8217;s a fair trade-off.</p>
</div>
<div class="paragraph">
<p>This leads us to an interesting discussion on the applications of neural language models,  such as Machine Translation, Natural Language Inference and of course Chatbots(!), as well as their limitations - namely the lack of adequate <em>attention</em> and <em>memory</em> mechanism, and the recent attempts to address them. But that is a separate topic, and by now I have likely already exhausted your attention budget for this blog. No biggie, I am about to follow up in a separate post. As for the original question, <em>Do I need Deep Learning for NLU/NLP problem?</em>, here is a quick rule of thumb:</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
For text prediction, a.k.a generative tasks, give Deep Learning a good look. For classification, a.k.a discriminative tasks, your mileage may vary.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In any case, remember, machine learning is an empirical discipline and no two datasets are alike. So you&#8217;ll never know the answer for certain until you try!</p>
</div>
<div class="sect3">
<h4 id="_references">References</h4>
<div class="paragraph">
<p>[1] <a href="https://arxiv.org/pdf/1607.01759v2.pdf">Bag of Tricks for Efficient Text Classification</a>, A. Joulin, E. Grave, P. Bojanowski, T. Mikolov</p>
</div>
<div class="paragraph">
<p>[2] <a href="https://github.com/facebookresearch/fastText">Facebook&#8217;s fastText</a> on Github.</p>
</div>
<div class="paragraph">
<p>[3] <a href="http://arxiv.org/abs/1608.04207v1">Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks</a>, Y. Adi, E. Kermany, Y. Belinkov, O. Lavi, Y. Goldberg</p>
</div>
<div class="paragraph">
<p>[4] <a href="http://arxiv.org/pdf/1606.02858v2.pdf">A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task</a>, D. Chen, J. Bolton, C. D. Manning</p>
</div>
<div class="paragraph">
<p>[5] <a href="http://arxiv.org/pdf/1606.01933v1.pdf">A Decomposable Attention Model for Natural Language Inference</a>, A. P. Parikh, O. Täckström, D. Das, J. Uszkoreit</p>
</div>
<div class="paragraph">
<p>[6] [Andrej Karpathy on human vs. machine image classification accuracy](<a href="https://plus.google.com/+AndrejKarpathy/posts/dwDNcBuWTWf" class="bare">https://plus.google.com/+AndrejKarpathy/posts/dwDNcBuWTWf</a>)</p>
</div>
<div class="paragraph">
<p>[7] Word2Vec</p>
</div>
<div class="paragraph">
<p>[8] Glove</p>
</div>
<div class="paragraph">
<p>[9] [Google Smart Reply](<a href="https://gmail.googleblog.com/2015/11/computer-respond-to-this-email.html" class="bare">https://gmail.googleblog.com/2015/11/computer-respond-to-this-email.html</a>)</p>
</div>
<div class="paragraph">
<p>[10] <a href="https://arxiv.org/abs/1602.02410v2">Exploring the limits of language modeling</a>, R. Jozefowicz, O. Vinyals, M. Schuster, N. Shazeer, Yonghui Wu.</p>
</div>
</div>
</div>]]></description><link>https://ilyaeck.github.io/2016/09/12/Natural-language-understanding-How-deep-is-too-deep.html</link><guid isPermaLink="true">https://ilyaeck.github.io/2016/09/12/Natural-language-understanding-How-deep-is-too-deep.html</guid><category><![CDATA[Deep Learning]]></category><category><![CDATA[ NLP]]></category><dc:creator><![CDATA[Ilya Eckstein ]]></dc:creator><pubDate>Mon, 12 Sep 2016 00:00:00 GMT</pubDate></item></channel></rss>